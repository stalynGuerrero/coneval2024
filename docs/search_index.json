[["index.html", "Manual de procesamiento del indicador de pobreza multidimensional mediante el uso de estimación de áreas pequeñas para México 2024 Introducción", " Manual de procesamiento del indicador de pobreza multidimensional mediante el uso de estimación de áreas pequeñas para México 2024 Andrés Gutiérrez1, Stalyn Guerrero2 2024-07-29 Introducción Este manual se desarrolla como una herramienta para detallar el paso a paso seguido por la Comisión Económica para América Latina y el Caribe (CEPAL) en la obtención de estimaciones del indicador multidimensional de pobreza en México. El proceso utiliza técnicas de estimación de áreas pequeñas y métodos de Monte Carlo. Aunque el procedimiento se describe con los códigos de 2020, el proceso para 2015 es similar, con pequeñas variaciones. Sin embargo, la esencia y los principios fundamentales son los mismos en ambos periodos. Experto Regional en Estadísticas Sociales - Comisión Económica para América Latina y el Caribe (CEPAL) - andres.gutierrez@cepal.org↩︎ Consultor - Comisión Económica para América Latina y el Caribe (CEPAL), guerrerostalyn@gmail.com↩︎ "],["respositodio-de-códigos.html", "Respositodio de códigos", " Respositodio de códigos En el siguiente enlace encontrará las rutinas de R desarrolladas para la estimación del IPM Descargar "],["librerias-de-r-y-otros-insumos.html", "Librerias de R y otros insumos", " Librerias de R y otros insumos En el siguiente apartado, se describe el conjunto de librerías utilizadas para el desarrollo de este proyecto, así como una breve descripción de las bases de datos empleadas. "],["librerías-utilizadas.html", "Librerías Utilizadas", " Librerías Utilizadas Manipulación y Transformación de Datos tidyverse: Conjunto de paquetes (incluyendo dplyr, ggplot2, tibble, readr, purrr, tidyr, y stringr) que facilitan la manipulación y visualización de datos de manera coherente y eficiente. data.table: Proporciona herramientas rápidas y eficientes para la manipulación de grandes conjuntos de datos tabulares. dplyr: Parte del tidyverse, facilita la manipulación de datos mediante verbos intuitivos como select, filter, mutate, summarize, y arrange. magrittr: Introduce el operador %&gt;%, permitiendo una escritura de código más clara y encadenada. purrr: Extiende las capacidades de programación funcional para trabajar con listas y vectores. furrr: Permite realizar operaciones paralelas utilizando purrr y future. stringr: Simplifica la manipulación de cadenas de caracteres mediante funciones intuitivas. labelled: Facilita la manipulación de datos etiquetados, comúnmente utilizados en encuestas y datos sociológicos. Lectura y Escritura de Datos openxlsx: Permite la creación, lectura y manipulación de archivos Excel sin depender de software adicional. haven: Permite leer y escribir datos en formatos usados por otros programas estadísticos como SPSS, Stata y SAS. readstata13: Especializado en la lectura de archivos Stata versión 13, asegurando compatibilidad con datos antiguos. Análisis de Datos de Encuestas survey: Proporciona herramientas para el análisis de datos de encuestas complejas, incluyendo ponderaciones y diseños de muestras. srvyr: Ofrece una interfaz más amigable basada en dplyr para trabajar con el paquete survey. TeachingSampling: Incluye métodos y herramientas para realizar muestreo en investigaciones educativas. samplesize4surveys: Facilita el cálculo del tamaño de muestra necesario para encuestas, asegurando resultados estadísticamente significativos. convey: Extiende survey para analizar medidas de desigualdad y pobreza en datos de encuestas. Modelado y Análisis Estadístico rstan: Interfaz de R para Stan, que realiza modelado bayesiano avanzado, permitiendo la creación de modelos complejos. lme4: Proporciona herramientas para ajustar y analizar modelos lineales y no lineales de efectos mixtos. car: Incluye diversas herramientas para la regresión aplicada y diagnósticos de modelos. randomForest: Implementa algoritmos de bosque aleatorio para clasificación y regresión. caret: Ofrece una amplia gama de herramientas para la creación y validación de modelos de aprendizaje automático. nortest: Contiene pruebas para evaluar la normalidad de los datos, esencial en muchos análisis estadísticos. Visualización de Datos ggplot2: Parte del tidyverse, es una potente herramienta para la visualización de datos basada en la gramática de gráficos. DataExplorer: Simplifica la exploración inicial y la generación de reportes de datos. thematic: Facilita la personalización de temas gráficos en ggplot2, permitiendo una estética consistente. patchwork: Permite combinar múltiples gráficos de ggplot2 en una única visualización coherente. tmap: Especializado en la creación de mapas temáticos, útil para visualizar datos geoespaciales. sf: Proporciona una estructura eficiente para manipular datos espaciales, facilitando la integración con ggplot2 y tmap. Informes y Reproducibilidad printr: Mejora el formato de la impresión de resultados en R Markdown, haciendo los informes más legibles. knitr: Herramienta clave para la creación de informes dinámicos y reproducibles, integrando código y texto. Integración con Otros Lenguajes reticulate: Facilita la interoperabilidad entre R y Python, permitiendo ejecutar código de Python dentro de un entorno de R. "],["bases-de-datos-utilizadas.html", "Bases de Datos Utilizadas", " Bases de Datos Utilizadas Para este proyecto, se emplearon diversas bases de datos que incluyen: Encuesta Nacional de Ingresos y Gastos de los Hogares (ENIGH): Proporciona información detallada sobre los ingresos y gastos de los hogares en México. Esta encuesta es crucial para entender los patrones de consumo y el bienestar económico de la población. Formulario Ampliado del Censo 2020: Ofrece datos sociodemográficos detallados a nivel de hogar y persona. Esta fuente es esencial para capturar una amplia gama de variables necesarias para el análisis multidimensional de la pobreza. Encuesta Intercensal de 2015: Complementa la información del censo con datos adicionales recopilados entre periodos censales. Proporciona una actualización intermedia de las condiciones demográficas y socioeconómicas. Imágenes Satelitales: Proveen datos geoespaciales esenciales para capturar la diversidad de las condiciones de vida en México. Estas imágenes ayudan a incorporar información espacial detallada en los modelos de estimación. Estas librerías y bases de datos son fundamentales para la implementación de la metodología de estimación del Índice de Pobreza Multidimensional (IPM) y otras carencias en los distintos municipios de México. "],["estructura-del-proyecto.html", "Estructura del Proyecto", " Estructura del Proyecto Para el desarrollo de los scripts, se estructuró un proyecto en R que cuenta con la siguiente organización: rcodes: En esta carpeta se encuentran los diferentes códigos desarrollados para cada año. Dentro de ella, hay subcarpetas específicas para 2020 y 2015, correspondientes a los años en los que se realizaron los cálculos de los indicadores de carencias y del Índice de Pobreza Multidimensional (IPM). Dentro de estas subcarpetas, los scripts están enumerados en orden de ejecución, como se muestra en la imagen a continuación: Cada subcarpeta contiene una serie de scripts organizados secuencialmente, asegurando que el proceso de cálculo y análisis se realice de manera ordenada y reproducible. Esta estructura facilita la identificación y ejecución de cada paso necesario para obtener los resultados del análisis de pobreza multidimensional. input: Esta carpeta contiene dos subcarpetas, una para 2015 y otra para 2020. En cada una de estas encontraremos la base de datos de la ENIGH, la encuesta ampliada del censo para el 2020 o la encuesta intercensal para el 2015, además de las variables predictoras a nivel de municipios. También incluye un archivo en formato CSV que contiene las líneas de pobreza para el año que se esté procesando. output: Esta carpeta sigue la misma estructura, con subcarpetas para 2015 y 2020. En cada una de estas subcarpetas encontraremos la carpeta de iteraciones, donde están disponibles los resultados de las iteraciones realizadas por cada estado para cada uno de los municipios. También dispone de una subcarpeta de modelos que contiene los modelos estimados para cada una de las carencias, así como algunos gráficos de validación. Además, encontraremos la carpeta de intermedias necesarias para el procesamiento de información o para el almacenamiento de algunos resultados. shapefile: Aquí están disponibles los shapefiles para la realización de mapas y descarga de información satelital, que son utilizados como covariables en la implementación del modelo. Esta organización permite mantener un flujo de trabajo claro y estructurado, donde cada script y conjunto de datos desempeñan un papel específico en el proceso general, desde la preparación de datos hasta la generación de resultados finales. "],["union_bases.html", "Capítulo 1 00_union_bases.R", " Capítulo 1 00_union_bases.R Para la ejecución del presente archivo, debe abrir el archivo 00_union_bases.R disponible en la ruta Rcodes/2020/00_union_bases.R. El código comienza limpiando el entorno de R y cargando varias bibliotecas esenciales para la manipulación y análisis de datos. Posteriormente, define un conjunto de variables a validar y obtiene listas de archivos de datos en formato .dta correspondientes a diferentes conjuntos de datos del censo 2020. A continuación, el código itera sobre estos archivos para leer, combinar y almacenar los datos de cada estado en archivos .rds individuales. Estos datos se combinan en un único dataframe que se guarda para su uso posterior. En la sección final, el código se centra en los datos de la ENIGH 2020. Lee los archivos de hogares y pobreza, y los combina utilizando un inner_join. Se seleccionan y renombran variables clave para asegurar la consistencia en el análisis. Finalmente, el dataframe combinado se guarda en un archivo .rds para facilitar el acceso y análisis futuros. rm(list = ls()) ################# ### Libraries ### ################# library(tidyverse) library(data.table) library(openxlsx) library(magrittr) library(DataExplorer) library(haven) library(purrr) library(furrr) library(labelled) cat(&quot;\\f&quot;) ############################################################### validar_var &lt;- c( &quot;ic_rezedu&quot;, &quot;ic_asalud&quot;, &quot;ic_segsoc&quot;, &quot;ic_cv&quot;, &quot;ic_sbv&quot;, &quot;ic_ali_nc&quot;, &quot;ictpc&quot; ) # Obtener la lista de archivos .dta file_muestra_censo_2020_estado &lt;- list.files( &quot;../input/2020/muestra_ampliada/SegSocial/SegSoc/&quot;, full.names = TRUE, pattern = &quot;dta$&quot; ) file_muestra_censo_2020_estado_complemento &lt;- list.files( &quot;../input/2020/muestra_ampliada/SegSocial/Complemento_SegSoc/&quot;, full.names = TRUE, pattern = &quot;dta$&quot; ) muestra_cuestionario_ampliado_censo_2020_estado &lt;- list.files( &quot;../input/2020/muestra_ampliada/IndicadoresCenso/&quot;, full.names = TRUE, pattern = &quot;dta$&quot; ) # Crear un dataframe vacío para almacenar los datos df &lt;- data.frame() # Iterar sobre cada archivo y leerlo for (ii in 1:32) { muestra_censo_2020_estado_ii &lt;- read_dta(file_muestra_censo_2020_estado[ii]) muestra_censo_2020_estado_complemento_ii &lt;- read_dta(file_muestra_censo_2020_estado_complemento[ii]) %&gt;% mutate(id_per = id_persona) muestra_cuestionario_ampliado_censo_2020_estado_ii &lt;- read_dta(muestra_cuestionario_ampliado_censo_2020_estado[ii]) muestra_censo &lt;- inner_join(muestra_censo_2020_estado_ii, muestra_censo_2020_estado_complemento_ii) %&gt;% select(-tamloc) %&gt;% inner_join(muestra_cuestionario_ampliado_censo_2020_estado_ii) saveRDS(muestra_censo, paste0(&quot;../output/2020/muestra_censo/depto_&quot;, ii, &quot;.rds&quot;)) df &lt;- bind_rows(df, muestra_censo) cat(file_muestra_censo_2020_estado[ii], &quot;\\n&quot;) } # Guardar el dataframe en un archivo .rds saveRDS(df, file = &quot;../output/2020/muestra_cuestionario_ampliado.rds&quot;) intersect(names(df), validar_var) dim(df) # &quot;ic_cv&quot; &quot;ic_sbv&quot; &quot;ic_rezedu&quot; &quot;ic_asalud&quot; ################################################################################ # enigh ################################################################################ # enigh_personas &lt;- read_dta(&quot;input/2020/enigh/base_personas_MEC20.dta&quot;) enigh_hogares &lt;- read_dta(&quot;../input/2020/enigh/base_hogares20.dta&quot;) enigh_pobreza &lt;- read_dta(&quot;../input/2020/enigh/pobreza_20.dta&quot;) %&gt;% select(-ent) n_distinct(enigh_pobreza$folioviv) n_distinct(enigh_hogares$folioviv) enigh &lt;- inner_join( enigh_pobreza, enigh_hogares, by = join_by( folioviv, foliohog, est_dis, upm, factor, rururb, ubica_geo ), suffix = c(&quot;_pers&quot;, &quot;_hog&quot;), ) enigh$ic_ali_nc enigh$ictpc_pers enigh$ictpc &lt;- enigh$ictpc_pers enigh$ic_segsoc saveRDS(enigh, file = &quot;../output/2020/enigh.rds&quot;) "],["descarga_satelitales.html", "Capítulo 2 01_Descarga_satelitales.R", " Capítulo 2 01_Descarga_satelitales.R Para la ejecución del presente archivo, debe abrir el archivo 01_Descarga_satelitales.R disponible en la ruta Rcodes/2020/01_Descarga_satelitales.R. Este código en R se enfoca en el procesamiento y análisis de datos geoespaciales utilizando una combinación de bibliotecas y herramientas de Google Earth Engine. La primera parte del script configura el entorno de trabajo, carga las librerías necesarias, y establece la conexión con Python mediante la biblioteca reticulate, esencial para trabajar con rgee, que es la interfaz de R para Google Earth Engine. En la segunda parte, se realiza la limpieza y transformación de datos espaciales. Se cargan y transforman archivos shapefiles de México a un sistema de referencia de coordenadas adecuado y se convierten a un formato MULTIPOLYGON. Luego, se extraen y procesan datos de imágenes satelitales para diversas variables como luminosidad, urbanización, y distancia a servicios de salud utilizando colecciones de imágenes de Google Earth Engine. Estos datos se agrupan por región y se guardan en archivos RDS para su análisis posterior. Finalmente, se combinan todos los datos procesados en un único dataframe y se escalan para prepararlos para su uso en modelos o análisis adicionales. rm(list = ls()) ################# ### Libraries ### ################# memory.limit(500000) library(tidyverse) library(sampling) library(rgee) # Conexión con Google Earth Engine library(sf) # Paquete para manejar datos geográficos library(concaveman) library(geojsonio) library(magrittr) library(furrr) library(readr) ####################################### ### configuración inicial de Python ### ####################################### rgee_environment_dir &lt;-reticulate::conda_list() rgee_environment_dir &lt;- rgee_environment_dir[rgee_environment_dir$name == &quot;rgee_py&quot;,2] reticulate::use_python(rgee_environment_dir, required = T ) reticulate::py_config() library(reticulate) # Conexión con Python rgee::ee_install_set_pyenv(py_path = rgee_environment_dir, py_env = &quot;rgee_py&quot;) Sys.setenv(RETICULATE_PYTHON = rgee_environment_dir) Sys.setenv(EARTHENGINE_PYTHON = rgee_environment_dir) rgee::ee_Initialize(drive = T) ################################################### ### Arreglar la shape ### ################################################### # plan(multisession, workers = 2) # # MEX &lt;- list.files(&quot;shapefile/2020/&quot;, pattern = &quot;shp$&quot;, # full.names = TRUE) %&gt;% # furrr::future_map(~read_sf(.x) %&gt;% # select(CVEGEO, NOM_ENT, NOMGEO,geometry), # .progress = TRUE) # # mi_crs &lt;- &quot;+proj=longlat +datum=WGS84&quot; # # # Transforma el polígono al nuevo CRS # MEX_trans &lt;- map(MEX, ~st_transform(.x, crs = mi_crs)) # MEX_trans &lt;- map(MEX_trans, ~st_cast(.x, &quot;MULTIPOLYGON&quot;)) # # MEX_trans &lt;- bind_rows(MEX_trans) # # # # stringi::stri_enc_detect(MEX_trans$NOMGEO) # # MEX_trans$NOMGEO &lt;- iconv(MEX_trans$NOMGEO, # to = &quot;UTF-8&quot;, from = &quot;ISO-8859-1&quot;) # # # st_write(MEX_trans, # &quot;shapefile/2020/MEX_2020.shp&quot;, # append = TRUE) # # rm(list = ls()) MEX &lt;- read_sf(&quot;../shapefile/2020/MEX_2020.shp&quot;) MEX %&lt;&gt;% mutate(ent = substr(CVEGEO,1,2)) ################### ### Luminosidad ### ################### #https://developers.google.com/earth-engine/datasets/catalog/NOAA_VIIRS_DNB_ANNUAL_V21#bands luces = ee$ImageCollection(&quot;NOAA/VIIRS/DNB/ANNUAL_V21&quot;) %&gt;% ee$ImageCollection$filterDate(&quot;2020-01-01&quot;, &quot;2021-01-01&quot;) %&gt;% ee$ImageCollection$map(function(x) x$select(&quot;average&quot;)) %&gt;% ee$ImageCollection$toBands() ee_print(luces) MEX_luces &lt;- map(unique(MEX$ent), ~tryCatch(ee_extract( x = luces, y = MEX[c(&quot;ent&quot;,&quot;CVEGEO&quot;)] %&gt;% filter(ent == .x), ee$Reducer$mean(), sf = FALSE ) , error = function(e)data.frame(ent = .x)) ) MEX_luces %&lt;&gt;% bind_rows() MEX_luces %&gt;% filter(is.na(X20200101_average)) %&gt;% select(CVEGEO) saveRDS(MEX_luces, &quot;../output/2020/Satelital/MEX_luces.rds&quot;) ################# ### Urbanismo ### ################# tiposuelo = ee$ImageCollection(&quot;COPERNICUS/Landcover/100m/Proba-V-C3/Global&quot;) %&gt;% ee$ImageCollection$filterDate(&quot;2019-01-01&quot;, &quot;2019-12-31&quot;) %&gt;% ee$ImageCollection$map(function(x) x$select(&quot;urban-coverfraction&quot;, &quot;crops-coverfraction&quot;)) %&gt;% ee$ImageCollection$toBands() ee_print(tiposuelo) MEX_urbano_cultivo &lt;- map(unique(MEX$CVEGEO), ~tryCatch(ee_extract( x = tiposuelo, y = MEX[c(&quot;ent&quot;,&quot;CVEGEO&quot;)] %&gt;% filter(CVEGEO == .x), ee$Reducer$mean(), sf = FALSE ) , error = function(e)data.frame(CVEGEO = .x)) ) MEX_urbano_cultivo %&lt;&gt;% bind_rows() MEX_urbano_cultivo %&gt;% filter(is.na(X2019_crops.coverfraction)) %&gt;% select(CVEGEO) MEX_urbano_cultivo %&gt;% filter(is.na(X2019_urban.coverfraction)) %&gt;% select(CVEGEO) saveRDS(MEX_urbano_cultivo, &quot;../output/2020/Satelital/MEX_urbano_cultivo.rds&quot;) ################# ### Distancia a hospitales ### ################# dist_salud = ee$Image(&#39;Oxford/MAP/accessibility_to_healthcare_2019&#39;) ee_print(dist_salud) MEX_dist_salud &lt;- map(unique(MEX$CVEGEO), ~tryCatch(ee_extract( x = dist_salud, y = MEX[c(&quot;ent&quot;,&quot;CVEGEO&quot;)] %&gt;% filter(CVEGEO == .x), ee$Reducer$mean(), sf = FALSE ) , error = function(e)data.frame(CVEGEO = .x)) ) MEX_dist_salud %&lt;&gt;% bind_rows() MEX_dist_salud %&gt;% filter(is.na(accessibility )) %&gt;% select(CVEGEO) MEX_dist_salud %&gt;% filter(is.na(accessibility_walking_only)) %&gt;% select(CVEGEO) saveRDS(MEX_dist_salud, &quot;../output/2020/Satelital/MEX_dist_salud.rds&quot;) ################# # CSP gHM: Global Human Modification ################# CSP_gHM = ee$ImageCollection(&#39;CSP/HM/GlobalHumanModification&#39;) ee_print(CSP_gHM) MEX_GHM &lt;- map(unique(MEX$CVEGEO), ~tryCatch(ee_extract( x = CSP_gHM, y = MEX[c(&quot;ent&quot;,&quot;CVEGEO&quot;)] %&gt;% filter(CVEGEO == .x), ee$Reducer$mean(), sf = FALSE ) , error = function(e)data.frame(CVEGEO = .x)) ) MEX_GHM %&lt;&gt;% bind_rows() MEX_GHM %&gt;% filter(is.na(X2016_gHM )) %&gt;% select(CVEGEO) saveRDS(MEX_GHM, &quot;../output/2020/Satelital/MEX_GHM.rds&quot;) ############### ### Guardar ### ############### statelevel_predictors_df &lt;- list.files(&quot;../output/2020/Satelital/&quot;, full.names = TRUE) %&gt;% map( ~ readRDS(file = .x)) %&gt;% reduce(., full_join) %&gt;% mutate_if(is.numeric, function(x) as.numeric(scale(x))) %&gt;% rename( cve_mun = CVEGEO, &quot;modifica_humana&quot; = X2016_gHM, &quot;acceso_hosp&quot; = accessibility, &quot;acceso_hosp_caminando&quot; = accessibility_walking_only, cubrimiento_urbano = X2019_urban.coverfraction, cubrimiento_cultivo = X2019_crops.coverfraction, luces_nocturnas = X20200101_average ) statelevel_predictors_df[apply(statelevel_predictors_df,1,function(x)any(is.na(x))),] %&gt;% view() saveRDS(statelevel_predictors_df, &quot;input/2020/predictores/statelevel_predictors_satelite.rds&quot;) "],["union_predictores.html", "Capítulo 3 02_Union_predictores.R", " Capítulo 3 02_Union_predictores.R Para la ejecución del presente archivo, debe abrir el archivo 02_Union_predictores.R disponible en la ruta Rcodes/2020/02_Union_predictores.R. Este script en R está orientado a la integración y limpieza de bases de datos a nivel municipal para el año 2020, combinando datos satelitales y de contexto. Primero, el entorno de trabajo se limpia y se cargan las bibliotecas necesarias para la manipulación y análisis de datos, incluyendo tidyverse, data.table, y openxlsx. En la primera parte, se carga una base de datos satelital en formato RDS, se renombra una columna para alinear los nombres y se eliminan columnas no necesarias. Luego, se obtienen los códigos municipales únicos de esta base de datos. A continuación, se carga una base de datos adicional en formato Stata (.dta), se convierten algunas variables a factores y se escalan las variables numéricas. Se realiza un análisis para identificar códigos municipales presentes en la base de datos satelital pero no en la de contexto, y se comprueba si hay columnas sin valores faltantes en la base de datos de contexto. Finalmente, se realiza un inner_join para combinar ambas bases de datos utilizando solo las columnas sin valores faltantes y se guarda el resultado en un archivo RDS para futuros análisis. ### Cleaning R environment ### rm(list = ls()) ################# ### Libraries ### ################# library(tidyverse) library(data.table) library(openxlsx) library(magrittr) library(DataExplorer) library(haven) library(purrr) library(labelled) cat(&quot;\\f&quot;) ################################################################################ # Lectura de bases de contexto 2020 ################################################################################ ## Covariables # Contexto_munXX : la base de datos contexto_20XX.dta contiene información de # variables a nivel municipal. # Cargar la base de datos satelital y renombrar la columna &quot;CVEGEO&quot; a &quot;cve_mun&quot; satelital &lt;- readRDS(&quot;../input/2020/predictores/statelevel_predictors_satelite.rds&quot;) %&gt;% rename(cve_mun = CVEGEO) %&gt;% mutate(ent = NULL) # Obtener los códigos municipales únicos de la base de datos satelital cod_mun &lt;- satelital %&gt;% distinct(cve_mun) # Cargar la base de datos &quot;Contexto_mun20&quot; en formato Stata y renombrar la columna &quot;CVEGEO&quot; a &quot;cve_mun&quot; Contexto_mun &lt;- read_dta(&quot;../input/2020/predictores/contexto_2020.dta&quot;) Contexto_mun %&gt;% as_factor() %&gt;% apply(., 2, n_distinct) %&gt;% sort() Contexto_mun$elec_mun19 Contexto_mun$elec_mun20 Contexto_mun$smg1 Contexto_mun$ql_porc_cpa_urb Contexto_mun$ql_porc_cpa_rur Contexto_mun$dec_geologicas Contexto_mun$dec_hidrometeo Contexto_mun %&lt;&gt;% as_factor() %&gt;% mutate_at( .vars = c( &quot;elec_mun19&quot;, &quot;elec_mun20&quot;, &quot;smg1&quot;, &quot;ql_porc_cpa_urb&quot;, &quot;ql_porc_cpa_rur&quot;, &quot;dec_geologicas&quot;, &quot;dec_hidrometeo&quot; ), as.factor ) %&gt;% mutate_if(is.numeric, function(x) as.numeric(scale(x))) # Realizar una anti_join para identificar códigos municipales presentes en &quot;cod_mun&quot; pero no en &quot;Contexto_mun&quot; anti_join(cod_mun, Contexto_mun) # Realizar un análisis para determinar si alguna columna de &quot;Contexto_mun&quot; no tiene valores faltantes paso &lt;- apply(Contexto_mun, 2, function(x) !any(is.na(x))) # Mostrar la frecuencia de columnas sin valores faltantes table(paso) # Realizar una inner_join entre las bases de datos &quot;satelital&quot; y &quot;Contexto_mun&quot; utilizando solo las columnas sin valores faltantes statelevel_predictors &lt;- inner_join(satelital, Contexto_mun[, paso]) # Obtener las dimensiones de la base de datos resultante dim(statelevel_predictors) ## Guardar saveRDS(statelevel_predictors,file = &quot;../input/2020/predictores/statelevel_predictors_df.rds&quot;) "],["estandarizar_muestra_cuestionario_ampliado.html", "Capítulo 4 03_Estandarizar_muestra_cuestionario_ampliado.R", " Capítulo 4 03_Estandarizar_muestra_cuestionario_ampliado.R Para la ejecución del presente archivo, debe abrir el archivo 02_Union_predictores.R disponible en la ruta Rcodes/2020/02_Union_predictores.R. El código ejecuta un análisis de datos en varias etapas. Primero, limpia el entorno de R eliminando todos los objetos actuales para empezar con un espacio de trabajo vacío. Luego, carga las bibliotecas necesarias, como tidyverse y data.table, que facilitan la manipulación y análisis de datos, así como la importación y exportación de archivos. A continuación, lee las bases de datos del censo de personas 2020 y de la Encuesta Nacional de Ingresos y Gastos de los Hogares (ENIGH). Estas bases se utilizan para identificar indicadores clave relacionados con la carencia en salud, calidad de vivienda, servicios básicos y rezago educativo. Seguidamente, valida y armoniza las variables entre ambas bases para garantizar que los códigos y etiquetas sean consistentes, comparando variables como códigos de entidad y municipio, áreas urbanas y rurales, sexo, edad, nivel educativo, discapacidad y lengua indígena. Posteriormente, estandariza las variables del censo para alinearlas con las de la encuesta y filtra los datos para eliminar inconsistencias. Finalmente, resume el conjunto de datos estandarizado por grupo, y guarda los datos procesados en dos versiones: una con los datos estandarizados y otra con los datos resumidos. ### Cleaning R environment ### rm(list = ls()) ################# ### Libraries ### ################# library(tidyverse) library(data.table) library(openxlsx) library(magrittr) library(DataExplorer) library(haven) library(purrr) library(labelled) library(sampling) cat(&quot;\\f&quot;) ################################################################################ # Lectura de bases censo persona 2020 ################################################################################ muestra_cuestionario_ampliado &lt;- readRDS( &quot;../output/2020/muestra_cuestionario_ampliado.rds&quot; ) enigh &lt;- readRDS(&quot;../output/2020/enigh.rds&quot;) muestra_cuestionario_ampliado %&gt;% dim() ################################################################################ # Identificando indicadores ################################################################################ # Indicador de carencia por acceso a los servicios de salud (CENSO) head(muestra_cuestionario_ampliado$ic_asalud) # Carencia por la calidad y espacios de la vivienda. (CENSO) attributes(muestra_cuestionario_ampliado$ic_cv)$label # Carencia por servicios básicos en la vivienda. (CENSO) attributes(muestra_cuestionario_ampliado$ic_sbv)$label # Carencia por rezago educativo. attributes( muestra_cuestionario_ampliado$ic_rezedu)$label ################################################################################ ## Validaciones para la armonización de variables ################################################################################ ## codigos de ent y municipio ## Encuesta n_distinct(enigh$ent) # cod_dam n_distinct(enigh$cve_mun) # cod_mun ## censo n_distinct(muestra_cuestionario_ampliado$ent) n_distinct(muestra_cuestionario_ampliado$cve_mun) ################################################################################ ## area ## Encuesta attributes(enigh$rururb) ## censo table(muestra_cuestionario_ampliado$rururb, useNA = &quot;a&quot;) # 0 Urbano # 1 Rural ################################################################################ ## Sexo ## Encuesta attributes(enigh$sexo) # 2 Mujer # 1 Hombre ## censo table(muestra_cuestionario_ampliado$sexo, useNA = &quot;a&quot;) # 0 Mujer # 1 Hombre ################################################################################ ## edad ## Encuesta attributes(enigh$edad) ## censo head(muestra_cuestionario_ampliado$edad_cat) ################################################################################ ## nivel_edu # ## Encuesta attributes(enigh$niv_ed) # 0 [Con primaria incompleta o menos] # 1 [Primaria completa o secundaria incompleta] # 2 [Secundaria completa o media superior incompleta] # 3 [Media superior completa o mayor nivel educativo] # NA Niños de 0 a 3 años ## censo attributes(muestra_cuestionario_ampliado$niv_ed) # 0 [Con primaria incompleta o menos] # 1 [Primaria completa o secundaria incompleta] # 2 [Secundaria completa o media superior incompleta] # 3 [Media superior completa o mayor nivel educativo] # NA Niños de 0 a 3 años ################################################################################ ## Discapacidad # ## se puede eliminar o solicitar que sea enviada en el mismo formato que la encuesta ## Encuesta attributes(enigh$discap) ## censo attributes(muestra_cuestionario_ampliado$discap) ################################################################################ ## Habla dialecto o lengua indígena ## Encuesta attributes(enigh$hli) ## censo attributes(muestra_cuestionario_ampliado$hli) ################################################################################ ## Estandarizando el censo ################################################################################ censo_sta &lt;- muestra_cuestionario_ampliado %&gt;% transmute( ent, cve_mun, upm, estrato, area = as.character(rururb), sexo = if_else(sexo == 1, &quot;1&quot;, &quot;2&quot;), edad = as.character(edad_cat), nivel_edu = haven::as_factor(niv_ed, levels = &quot;values&quot;), discapacidad = as.character(discap), discapacidad = if_else(is.na(discapacidad), &quot;0&quot;, discapacidad), hlengua = as.character(hli), hlengua = if_else(is.na(hlengua), &quot;0&quot;, hlengua), ic_asalud= haven::as_factor(ic_asalud, levels = &quot;values&quot;), ic_cv = haven::as_factor(ic_cv, levels = &quot;values&quot;), ic_sbv = haven::as_factor(ic_sbv, levels = &quot;values&quot;), ic_rezedu = haven::as_factor(ic_rezedu, levels = &quot;values&quot;), factor ) %&gt;% filter( !cve_mun %in% c(&quot;04012&quot;, &quot;07125&quot;, &quot;29048&quot;)) censo_sta2 &lt;- censo_sta %&gt;% filter( !is.na(nivel_edu), !is.na(edad), !is.na(ic_sbv), !is.na(ic_cv), !is.na(ic_rezedu), !is.na(ic_asalud), ) sum(censo_sta2$factor) / sum(censo_sta$factor) #Se guarda el conjunto de datos estandarizado: saveRDS(censo_sta2,&quot;../output/2020/encuesta_ampliada.rds&quot;) #Se resumen los datos por grupo: censo_sta2 %&lt;&gt;% group_by( ent, cve_mun, area, hlengua, sexo, edad, nivel_edu, discapacidad, ic_asalud, ic_cv, ic_sbv, ic_rezedu ) %&gt;% summarise(n = sum(factor), .groups = &quot;drop&quot;) #Se guarda el conjunto de datos resumido: saveRDS(censo_sta2, &quot;../input/2020/muestra_ampliada/muestra_cuestionario_ampliado.rds&quot;) "],["armonizar_encuesta.html", "Capítulo 5 04_Armonizar_encuesta.R", " Capítulo 5 04_Armonizar_encuesta.R Para la ejecución del presente análisis, se debe abrir el archivo 04_Armonizar_encuesta.R disponible en la ruta Rcodes/2020/04_Armonizar_encuesta.R. El código realiza un análisis completo de datos en varias etapas. Inicialmente, se eliminan todos los objetos del entorno de R para asegurar que el análisis comience con una pizarra limpia. Luego, se cargan las bibliotecas necesarias para el análisis, que incluyen herramientas para la manipulación de datos y la importación/exportación de archivos. A continuación, se leen las bases de datos del censo de personas 2020 y la Encuesta Nacional de Ingresos y Gastos de los Hogares (ENIGH), que se utilizan para identificar y verificar indicadores de carencias sociales. Posteriormente, se definen y validan las variables clave de la encuesta, como códigos de entidad, municipio, área, sexo, edad, nivel educativo, discapacidad y lengua indígena. Luego, se estandarizan las variables de la encuesta para que coincidan con las del censo, se filtran los datos para eliminar inconsistencias, y se guarda el conjunto de datos estandarizado. Además, se actualiza la tabla censal utilizando la técnica de calibración IPFP (Iterative Proportional Fitting Procedure) para asegurar que las distribuciones marginales de las variables estandarizadas coincidan con las del censo. Finalmente, se generan histogramas y gráficos de dispersión para visualizar los resultados de la calibración y se guarda el conjunto de datos ampliado. ### Cleaning R environment ### rm(list = ls()) ################# ### Libraries ### ################# library(tidyverse) library(data.table) library(openxlsx) library(magrittr) library(DataExplorer) library(haven) library(purrr) library(labelled) library(sampling) cat(&quot;\\f&quot;) ################################################################################ # Lectura de la base Pobreza_15.dta ################################################################################ encuesta_ampliada &lt;- readRDS(&quot;../input/2020/muestra_ampliada/muestra_cuestionario_ampliado.rds&quot;) # Indicadores_MECXX: La base de datos Pobreza_15.dta contiene la información de # variables de carencias sociales a nivel individual (Utiliza como insumo la # información del MEC) enigh &lt;- readRDS(&quot;output//2020/enigh.rds&quot;) n_distinct(enigh$ent) # cod_dam n_distinct(enigh$cve_mun) # cod_mun ################################################################################ ## Definiciones para la encuesta ################################################################################ # codigo municipio # area urabo o rural enigh %&gt;% group_by(rururb) %&gt;% summarise(n = sum(factor)) enigh %&lt;&gt;% mutate( area = haven::as_factor(rururb, levels = &quot;values&quot;), area = as.character(area) ) enigh %&gt;% distinct(rururb,area) # Sexo enigh %&gt;% group_by(sexo) %&gt;% summarise(n = sum(factor)) # 2 Mujer # 1 Hombre # Edad enigh %&gt;% group_by(edad) %&gt;% summarise(n = sum(factor)) encuesta_ampliada %&gt;% distinct(edad) # 1 Menor de 14 años # 2 15 a 29 años # 3 30 a 44 años # 4 45 a 64 años # 5 65 años o más enigh %&lt;&gt;% mutate(g_edad = case_when(edad &lt;= 14 ~ &quot;1&quot;, # 0 a 14 edad &lt;= 29 ~ &quot;2&quot;, # 15 a 29 edad &lt;= 44 ~ &quot;3&quot;, # 30 a 44 edad &lt;= 64 ~ &quot;4&quot;, # 45 a 64 edad &gt; 64 ~ &quot;5&quot;, # 65 o mas TRUE ~ NA_character_)) enigh %&gt;% group_by(g_edad) %&gt;% summarise(n = sum(factor)) # nivel educativo enigh %&gt;% group_by(niv_ed) %&gt;% summarise(n = sum(factor),.groups = &quot;drop&quot;) %&gt;% mutate(prop = n / sum(n)) enigh %&gt;% mutate(nivel_edu = haven::as_factor(niv_ed, levels = &quot;values&quot;)) %&gt;% group_by(nivel_edu, g_edad) %&gt;% summarise(n = sum(factor)) %&gt;% data.frame() # 0 [Con primaria incompleta o menos] 32682451 # 1 [Primaria completa o secundaria incompleta] 21725064 # 2 [Secundaria completa o media superior incompleta] 31740188 # 3 [Media superior completa o mayor nivel educativo] 36430137 # NA 4849854 Niños de 0 a 3 años enigh %&lt;&gt;% mutate( nivel_edu = haven::as_factor(niv_ed, levels = &quot;values&quot;), nivel_edu = as.character(nivel_edu) ) enigh %&gt;% distinct(niv_ed,nivel_edu) # Discapacidad enigh %&gt;% group_by(discap) %&gt;% summarise(n = sum(factor)) enigh %&lt;&gt;% mutate( discapacidad = haven::as_factor(discap, levels = &quot;values&quot;), discapacidad = as.character(discapacidad) ) enigh %&gt;% distinct(discap,discapacidad) # Habla dialecto o lengua indígena attributes(enigh$hli) enigh %&gt;% group_by(hli) %&gt;% summarise(n = sum(factor)) enigh %&lt;&gt;% mutate( hlengua = haven::as_factor(hli, levels = &quot;values&quot;), hlengua = as.character(hlengua) ) enigh %&gt;% distinct(hlengua,hli) ###################################################### hist(log(enigh$ictpc)) # Indicador de carencia por acceso a servicios de salud attributes(enigh$ic_segsoc) # Indicador de carencia por acceso a la alimentación nutritiva y de calidad attributes(enigh$ic_ali_nc) enigh %&gt;% group_by(ic_segsoc) %&gt;% summarise(n = sum(factor)) ################################################################################ encuesta_sta &lt;- enigh %&gt;% transmute( ent = str_pad( string = ent, width = 2, pad = &quot;0&quot; ), cve_mun, area, sexo, edad = ifelse(is.na(g_edad), &quot;99&quot;, g_edad), nivel_edu = ifelse(is.na(nivel_edu), &quot;99&quot;, nivel_edu), discapacidad = ifelse(is.na(discapacidad), &quot;0&quot;, discapacidad), hlengua = ifelse(is.na(hlengua), &quot;0&quot;, hlengua), ## Variable de estudio ictpc = as.numeric(ictpc), ic_segsoc = as.numeric(ic_segsoc), ic_ali_nc = as.numeric(ic_ali_nc), ic_rezedu = as.numeric(ic_segsoc), ic_asalud = as.numeric(ic_segsoc), ic_sbv = as.numeric(ic_sbv_hog), ic_cv = as.numeric(ic_cv_hog), ## Variables diseño estrato = est_dis, upm = upm, fep = factor ) map(c( &quot;ent&quot;, &quot;cve_mun&quot;, &quot;area&quot;, &quot;sexo&quot;, &quot;edad&quot;, &quot;nivel_edu&quot;, &quot;hlengua&quot;, &quot;discapacidad&quot;, &quot;ic_segsoc&quot;, &quot;ic_ali_nc&quot; ), function(x) { encuesta_sta %&gt;% group_by_at(x ) %&gt;% summarise(Nd = sum(fep)) %&gt;% mutate(N = sum(Nd), prop = Nd / N) }) #Se guarda el conjunto de datos saveRDS(encuesta_sta, file = &quot;../input/2020/enigh/encuesta_sta.rds&quot;) # Actualización de tabla censal- IPFP ------------------------------------- names_cov &lt;- c(&quot;ent&quot;, &quot;cve_mun&quot;, &quot;area&quot;, &quot;sexo&quot;, &quot;edad&quot;, &quot;discapacidad&quot;, &quot;hlengua&quot;) names_cov &lt;- names_cov[names_cov %in% names(encuesta_sta)] num_cat_censo &lt;- apply(encuesta_ampliada[names_cov], MARGIN = 2, function(x) length(unique(x))) num_cat_sample &lt;- apply(encuesta_sta[names_cov], MARGIN = 2, function(x) length(unique(x))) names_cov &lt;- names_cov[num_cat_censo==num_cat_sample] # MatrizCalibrada creada únicamente para los niveles completos # IMPORTANTE: Excluir las covariables que tengan niveles incompletos auxSuma &lt;- function(dat, col, ni){ dat %&gt;% ungroup() %&gt;% select(all_of(col)) %&gt;% fastDummies::dummy_cols(remove_selected_columns = TRUE) %&gt;% mutate_all(~.*ni) %&gt;% colSums() } N.g &lt;- map(names_cov, ~ auxSuma(encuesta_sta, col = .x, ni = encuesta_sta$fep)) %&gt;% unlist() N_censo.g &lt;- map(names_cov, ~ auxSuma(encuesta_ampliada, col = .x, ni = encuesta_ampliada$n)) %&gt;% unlist() names_xk &lt;- intersect(names(N.g),names(N_censo.g)) N.g &lt;- N.g[names_xk] N_censo.g &lt;- N_censo.g[names_xk] Xk &lt;- encuesta_ampliada %&gt;% ungroup() %&gt;% select(all_of(names_cov)) %&gt;% fastDummies::dummy_cols(remove_selected_columns = TRUE) %&gt;% select(all_of(names_xk)) gk &lt;- calib(Xs = Xk, d = encuesta_ampliada$n, total = N.g, method=&quot;linear&quot;) # linear primera opcion checkcalibration(Xs = Xk, d = encuesta_ampliada$n, total = N.g, g = gk) hist(gk) summary(gk) ggplot(data.frame(x = gk), aes(x = x)) + geom_histogram(binwidth = diff(range(gk))/20, color = &quot;black&quot;, alpha = 0.7) + labs(title = &quot;&quot;, x = &quot;&quot;, y = &quot;&quot;) + theme_minimal() + theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) n1 &lt;- encuesta_ampliada$n*gk ggplot(data = data.frame(x = encuesta_ampliada$n, y = n1), aes(x = x, y = y)) + geom_point() + # Agregar puntos geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + labs(title = &quot;&quot;, x = &quot;Conteo censales antes&quot;, y = &quot;Conteos censales despues&quot;) + theme_minimal(20) encuesta_ampliada$n &lt;- encuesta_ampliada$n*gk #Se guarda el conjunto de datos ampliado: saveRDS(encuesta_ampliada, &quot;../output/2020/encuesta_ampliada.rds&quot;) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
